"""
Replicateë¥¼ ì‚¬ìš©í•œ FLUX LoRA í•™ìŠµ ë° ì¶”ë¡  í†µí•© ìŠ¤í¬ë¦½íŠ¸
"""

import replicate
import requests
import zipfile
import os
from PIL import Image
import time

class FluxLoRATrainer:
    def __init__(self, api_token):
        os.environ["REPLICATE_API_TOKEN"] = api_token
        
    def prepare_dataset(self, image_folder, output_zip="dataset.zip", 
                       trigger_word="TOK", captions=None):
        """
        ì´ë¯¸ì§€ í´ë”ë¥¼ í•™ìŠµìš© ZIP íŒŒì¼ë¡œ ë³€í™˜
        
        Args:
            image_folder: ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
            output_zip: ì¶œë ¥ ZIP íŒŒì¼ëª…
            trigger_word: LoRA íŠ¸ë¦¬ê±° ì›Œë“œ
            captions: ì´ë¯¸ì§€ë³„ ìº¡ì…˜ ë”•ì…”ë„ˆë¦¬ (ì„ íƒì‚¬í•­)
        """
        with zipfile.ZipFile(output_zip, 'w') as zf:
            for filename in os.listdir(image_folder):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                    img_path = os.path.join(image_folder, filename)
                    
                    # ì´ë¯¸ì§€ ê²€ì¦ ë° ë³€í™˜
                    img = Image.open(img_path)
                    if img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    # ZIPì— ì´ë¯¸ì§€ ì¶”ê°€
                    zf.write(img_path, f"{filename}")
                    
                    # ìº¡ì…˜ ì¶”ê°€
                    base_name = os.path.splitext(filename)[0]
                    if captions and filename in captions:
                        caption = captions[filename]
                    else:
                        caption = f"a photo of {trigger_word}"
                    
                    zf.writestr(f"{base_name}.txt", caption)
        
        print(f"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ: {output_zip}")
        return output_zip
    
    def train_lora(self, dataset_zip, model_name, trigger_word="TOK", 
                   steps=1000, learning_rate=4e-4):
        """
        LoRA í•™ìŠµ ì‹œì‘
        
        Args:
            dataset_zip: í•™ìŠµ ë°ì´í„° ZIP íŒŒì¼ ê²½ë¡œ
            model_name: ì €ì¥í•  ëª¨ë¸ ì´ë¦„
            trigger_word: íŠ¸ë¦¬ê±° ì›Œë“œ
            steps: í•™ìŠµ ìŠ¤í… ìˆ˜
            learning_rate: í•™ìŠµë¥ 
        
        Returns:
            í•™ìŠµ ID
        """
        # ZIP íŒŒì¼ì„ URLë¡œ ì—…ë¡œë“œ (GitHub, Google Drive, ë˜ëŠ” ì„ì‹œ í˜¸ìŠ¤íŒ…)
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ file.io ì‚¬ìš©
        print("ğŸ“¤ ë°ì´í„°ì…‹ ì—…ë¡œë“œ ì¤‘...")
        
        with open(dataset_zip, 'rb') as f:
            response = requests.post('https://file.io', files={'file': f})
            dataset_url = response.json()['link']
        
        print(f"ğŸ“¦ ë°ì´í„°ì…‹ URL: {dataset_url}")
        
        # í•™ìŠµ ì‹œì‘
        print("ğŸš€ LoRA í•™ìŠµ ì‹œì‘...")
        
        training = replicate.trainings.create(
            version="ostris/flux-dev-lora-trainer:4ffd32160efd92e956d39c5338a9b8fbafca58e03f791f6d8011f3e20e8ea6fa",
            input={
                "input_images": dataset_url,
                "trigger_word": trigger_word,
                "steps": steps,
                "learning_rate": learning_rate,
                "rank": 32,
                "optimizer": "adamw8bit",
                "batch_size": 1,
                "resolution": "512,768,1024",
                "autocaption": True,  # ìë™ ìº¡ì…˜ ìƒì„±
                "autocaption_prefix": trigger_word,
            },
            destination=f"{os.environ.get('REPLICATE_USERNAME', 'user')}/{model_name}"
        )
        
        print(f"ğŸ“Š í•™ìŠµ ID: {training.id}")
        print(f"ğŸ“ ìƒíƒœ: {training.status}")
        print(f"ğŸ’° ì˜ˆìƒ ë¹„ìš©: $2-3")
        print(f"â±ï¸ ì˜ˆìƒ ì‹œê°„: 20-30ë¶„")
        
        return training
    
    def wait_for_training(self, training):
        """í•™ìŠµ ì™„ë£Œ ëŒ€ê¸°"""
        print("\nâ³ í•™ìŠµ ì§„í–‰ ì¤‘...")
        
        while training.status not in ["succeeded", "failed", "canceled"]:
            time.sleep(30)
            training.reload()
            print(f"   ìƒíƒœ: {training.status} - {time.strftime('%H:%M:%S')}")
        
        if training.status == "succeeded":
            print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
            print(f"ğŸ‰ ëª¨ë¸: {training.output['version']}")
            return training.output['version']
        else:
            print(f"\nâŒ í•™ìŠµ ì‹¤íŒ¨: {training.status}")
            if training.error:
                print(f"   ì—ëŸ¬: {training.error}")
            return None
    
    def generate_image(self, model_version, prompt, num_images=1):
        """í•™ìŠµëœ LoRAë¡œ ì´ë¯¸ì§€ ìƒì„±"""
        output = replicate.run(
            model_version,
            input={
                "prompt": prompt,
                "num_outputs": num_images,
                "aspect_ratio": "1:1",
                "output_format": "png",
                "guidance": 3.5,
                "num_inference_steps": 28,
            }
        )
        
        return output

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # 1. ì´ˆê¸°í™”
    trainer = FluxLoRATrainer(api_token="r8_YOUR_TOKEN")
    
    # 2. ë°ì´í„°ì…‹ ì¤€ë¹„
    # ì´ë¯¸ì§€ í´ë” êµ¬ì¡°:
    # my_images/
    #   â”œâ”€â”€ img1.jpg
    #   â”œâ”€â”€ img2.jpg
    #   â””â”€â”€ img3.jpg
    
    dataset = trainer.prepare_dataset(
        image_folder="my_images",
        trigger_word="MYCHAR",
        captions={
            "img1.jpg": "MYCHAR smiling, portrait photo",
            "img2.jpg": "MYCHAR wearing suit, professional photo",
            "img3.jpg": "MYCHAR in casual clothes, outdoor photo"
        }
    )
    
    # 3. í•™ìŠµ ì‹œì‘
    training = trainer.train_lora(
        dataset_zip=dataset,
        model_name="my-character-flux-lora",
        trigger_word="MYCHAR",
        steps=1000
    )
    
    # 4. í•™ìŠµ ì™„ë£Œ ëŒ€ê¸°
    model_version = trainer.wait_for_training(training)
    
    if model_version:
        # 5. ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ¨ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        
        test_prompts = [
            "MYCHAR as a wizard, fantasy art, magical",
            "MYCHAR in cyberpunk style, neon lights",
            "MYCHAR portrait, oil painting style",
            "MYCHAR wearing kimono in japanese garden"
        ]
        
        for i, prompt in enumerate(test_prompts):
            print(f"\nìƒì„± ì¤‘: {prompt}")
            output = trainer.generate_image(model_version, prompt)
            
            # ì´ë¯¸ì§€ ì €ì¥
            for j, image_url in enumerate(output):
                img_data = requests.get(image_url).content
                with open(f"output_{i}_{j}.png", "wb") as f:
                    f.write(img_data)
                print(f"   âœ… ì €ì¥: output_{i}_{j}.png")
    
    print("\nğŸ‰ ì™„ë£Œ!")
    print(f"ğŸ’¡ ë‹¤ìŒì— ì‚¬ìš©í•˜ë ¤ë©´: replicate.run('{model_version}', input={{...}})")