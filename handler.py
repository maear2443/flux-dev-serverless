import runpod
import torch
import base64
from io import BytesIO
from PIL import Image
from diffusers import FluxPipeline, DPMSolverMultistepScheduler
import cv2
import numpy as np

# GPU ë©”ëª¨ë¦¬ ìµœì í™”
torch.cuda.empty_cache()

# ëª¨ë¸ ë¡œë“œ (ì „ì—­ ë³€ìˆ˜ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ)
print("ğŸ”§ ëª¨ë¸ ë¡œë“œ ì¤‘...")
pipe = FluxPipeline.from_pretrained(
    "/app/models/flux-dev",
    torch_dtype=torch.float16,
    variant="fp16"
).to("cuda")

# ìŠ¤ì¼€ì¤„ëŸ¬ ìµœì í™”
pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)

# VAE ìµœì í™”
pipe.enable_vae_slicing()
pipe.enable_vae_tiling()

def upscale_image(image, scale=2):
    """ê°„ë‹¨í•œ ì—…ìŠ¤ì¼€ì¼ë§ í•¨ìˆ˜"""
    # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
    img_array = np.array(image)
    
    # OpenCVë¡œ ì—…ìŠ¤ì¼€ì¼
    height, width = img_array.shape[:2]
    new_dimensions = (width * scale, height * scale)
    
    # INTER_CUBIC ë³´ê°„ë²• ì‚¬ìš©
    upscaled = cv2.resize(img_array, new_dimensions, interpolation=cv2.INTER_CUBIC)
    
    # ë‹¤ì‹œ PIL Imageë¡œ ë³€í™˜
    return Image.fromarray(upscaled)

def handler(job):
    """RUNPOD í•¸ë“¤ëŸ¬ í•¨ìˆ˜"""
    try:
        job_input = job["input"]
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        prompt = job_input.get("prompt", "beautiful landscape")
        negative_prompt = job_input.get("negative_prompt", "")
        width = job_input.get("width", 1024)
        height = job_input.get("height", 1024)
        num_inference_steps = job_input.get("steps", 28)
        guidance_scale = job_input.get("guidance_scale", 3.5)
        seed = job_input.get("seed", -1)
        upscale = job_input.get("upscale", False)
        upscale_factor = job_input.get("upscale_factor", 2)
        
        # ì‹œë“œ ì„¤ì •
        if seed == -1:
            seed = torch.randint(0, 2**32, (1,)).item()
        
        generator = torch.Generator(device="cuda").manual_seed(seed)
        
        # ì´ë¯¸ì§€ ìƒì„±
        with torch.cuda.amp.autocast():            image = pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                width=width,
                height=height,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                generator=generator
            ).images[0]
        
        # ì—…ìŠ¤ì¼€ì¼ë§ (ìš”ì²­ ì‹œ)
        if upscale:
            image = upscale_image(image, upscale_factor)
        
        # Base64 ì¸ì½”ë”©
        buffered = BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        
        return {
            "image": img_str,
            "seed": seed,
            "width": image.width,
            "height": image.height
        }
        
    except Exception as e:
        return {"error": str(e)}

# RUNPOD ì„œë²„ë¦¬ìŠ¤ ì‹œì‘
runpod.serverless.start({"handler": handler})